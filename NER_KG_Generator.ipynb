{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2vllqTVouqL",
        "outputId": "42824ae2-9122-4218-d555-473b52b20b38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m929.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting filelock (from transformers)\n",
            "  Downloading filelock-3.13.4-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
            "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting numpy>=1.17 (from transformers)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from transformers) (24.0)\n",
            "Collecting pyyaml>=5.1 (from transformers)\n",
            "  Downloading PyYAML-6.0.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers)\n",
            "  Downloading regex-2023.12.25-cp311-cp311-macosx_10_9_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m436.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting requests (from transformers)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.15.2-cp311-cp311-macosx_10_12_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting safetensors>=0.4.1 (from transformers)\n",
            "  Downloading safetensors-0.4.2-cp311-cp311-macosx_10_12_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting tqdm>=4.27 (from transformers)\n",
            "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m425.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.19.3->transformers)\n",
            "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
            "  Downloading charset_normalizer-3.3.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata (33 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->transformers)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
            "  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
            "  Downloading certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Downloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-macosx_10_9_x86_64.whl (20.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.1-cp311-cp311-macosx_10_9_x86_64.whl (187 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.9/187.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading regex-2023.12.25-cp311-cp311-macosx_10_9_x86_64.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.4.2-cp311-cp311-macosx_10_12_x86_64.whl (426 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.3/426.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.2-cp311-cp311-macosx_10_12_x86_64.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.13.4-py3-none-any.whl (11 kB)\n",
            "Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m677.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.3.2-cp311-cp311-macosx_10_9_x86_64.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m954.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: urllib3, tqdm, safetensors, regex, pyyaml, numpy, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed certifi-2024.2.2 charset-normalizer-3.3.2 filelock-3.13.4 fsspec-2024.3.1 huggingface-hub-0.22.2 idna-3.7 numpy-1.26.4 pyyaml-6.0.1 regex-2023.12.25 requests-2.31.0 safetensors-0.4.2 tokenizers-0.15.2 tqdm-4.66.2 transformers-4.39.3 urllib3-2.2.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from datasets) (3.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
            "Collecting pyarrow>=12.0.0 (from datasets)\n",
            "  Downloading pyarrow-15.0.2-cp311-cp311-macosx_10_15_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pandas (from datasets)\n",
            "  Downloading pandas-2.2.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: requests>=2.19.0 in ./.venv/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in ./.venv/lib/python3.11/site-packages (from datasets) (4.66.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.2.0,>=2023.1.0 (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.9.4-cp311-cp311-macosx_10_9_x86_64.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in ./.venv/lib/python3.11/site-packages (from datasets) (0.22.2)\n",
            "Requirement already satisfied: packaging in ./.venv/lib/python3.11/site-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
            "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.4.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (12 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.0.5-cp311-cp311-macosx_10_9_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.9.4-cp311-cp311-macosx_10_9_x86_64.whl.metadata (31 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.19.4->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1 (from pandas->datasets)\n",
            "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
            "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.9.4-cp311-cp311-macosx_10_9_x86_64.whl (402 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.3/402.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-15.0.2-cp311-cp311-macosx_10_15_x86_64.whl (27.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.2/27.2 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.2-cp311-cp311-macosx_10_9_x86_64.whl (12.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Downloading xxhash-3.4.1-cp311-cp311-macosx_10_9_x86_64.whl (31 kB)\n",
            "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m661.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading frozenlist-1.4.1-cp311-cp311-macosx_10_9_x86_64.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m652.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.0.5-cp311-cp311-macosx_10_9_x86_64.whl (30 kB)\n",
            "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading yarl-1.9.4-cp311-cp311-macosx_10_9_x86_64.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m949.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytz, xxhash, tzdata, pyarrow-hotfix, pyarrow, multidict, fsspec, frozenlist, dill, attrs, yarl, pandas, multiprocess, aiosignal, aiohttp, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.3.1\n",
            "    Uninstalling fsspec-2024.3.1:\n",
            "      Successfully uninstalled fsspec-2024.3.1\n",
            "Successfully installed aiohttp-3.9.4 aiosignal-1.3.1 attrs-23.2.0 datasets-2.18.0 dill-0.3.8 frozenlist-1.4.1 fsspec-2024.2.0 multidict-6.0.5 multiprocess-0.70.16 pandas-2.2.2 pyarrow-15.0.2 pyarrow-hotfix-0.6 pytz-2024.1 tzdata-2024.1 xxhash-3.4.1 yarl-1.9.4\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting neo4j\n",
            "  Using cached neo4j-5.19.0-py3-none-any.whl\n",
            "Requirement already satisfied: pytz in ./.venv/lib/python3.11/site-packages (from neo4j) (2024.1)\n",
            "Installing collected packages: neo4j\n",
            "Successfully installed neo4j-5.19.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.1.16-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
            "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
            "  Downloading SQLAlchemy-2.0.29-cp311-cp311-macosx_10_9_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.11/site-packages (from langchain) (3.9.4)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.32 (from langchain)\n",
            "  Downloading langchain_community-0.0.32-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting langchain-core<0.2.0,>=0.1.42 (from langchain)\n",
            "  Downloading langchain_core-0.1.42-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.45-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in ./.venv/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
            "Collecting pydantic<3,>=1 (from langchain)\n",
            "  Downloading pydantic-2.7.0-py3-none-any.whl.metadata (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.4/103.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
            "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
            "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.42->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.0-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pydantic-core==2.18.1 (from pydantic<3,>=1->langchain)\n",
            "  Downloading pydantic_core-2.18.1-cp311-cp311-macosx_10_12_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
            "  Downloading greenlet-3.0.3-cp311-cp311-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langchain_community-0.0.32-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.1.42-py3-none-any.whl (287 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.5/287.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Downloading langsmith-0.1.45-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.2/104.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.7.0-py3-none-any.whl (407 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.9/407.9 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.18.1-cp311-cp311-macosx_10_12_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading SQLAlchemy-2.0.29-cp311-cp311-macosx_10_9_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
            "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Downloading greenlet-3.0.3-cp311-cp311-macosx_11_0_universal2.whl (271 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.7/271.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m891.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.0-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.1/252.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m563.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: tenacity, pydantic-core, packaging, orjson, mypy-extensions, jsonpointer, greenlet, annotated-types, typing-inspect, SQLAlchemy, pydantic, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed SQLAlchemy-2.0.29 annotated-types-0.6.0 dataclasses-json-0.6.4 greenlet-3.0.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.16 langchain-community-0.0.32 langchain-core-0.1.42 langchain-text-splitters-0.0.1 langsmith-0.1.45 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.10.0 packaging-23.2 pydantic-2.7.0 pydantic-core-2.18.1 tenacity-8.2.3 typing-inspect-0.9.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: langchain_community in ./.venv/lib/python3.11/site-packages (0.0.32)\n",
            "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.11/site-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.11/site-packages (from langchain_community) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.11/site-packages (from langchain_community) (3.9.4)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./.venv/lib/python3.11/site-packages (from langchain_community) (0.6.4)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.41 in ./.venv/lib/python3.11/site-packages (from langchain_community) (0.1.42)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in ./.venv/lib/python3.11/site-packages (from langchain_community) (0.1.45)\n",
            "Requirement already satisfied: numpy<2,>=1 in ./.venv/lib/python3.11/site-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.11/site-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in ./.venv/lib/python3.11/site-packages (from langchain_community) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.41->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in ./.venv/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.41->langchain_community) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in ./.venv/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.41->langchain_community) (2.7.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in ./.venv/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.41->langchain_community) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.41->langchain_community) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.41->langchain_community) (2.18.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.29.2-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.11/site-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in ./.venv/lib/python3.11/site-packages (from accelerate) (5.9.8)\n",
            "Requirement already satisfied: pyyaml in ./.venv/lib/python3.11/site-packages (from accelerate) (6.0.1)\n",
            "Collecting torch>=1.10.0 (from accelerate)\n",
            "  Downloading torch-2.2.2-cp311-none-macosx_10_9_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: huggingface-hub in ./.venv/lib/python3.11/site-packages (from accelerate) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in ./.venv/lib/python3.11/site-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Collecting sympy (from torch>=1.10.0->accelerate)\n",
            "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch>=1.10.0->accelerate)\n",
            "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting jinja2 (from torch>=1.10.0->accelerate)\n",
            "  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: fsspec in ./.venv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.11/site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.10.0->accelerate)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Collecting mpmath>=0.19 (from sympy->torch>=1.10.0->accelerate)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading accelerate-0.29.2-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.4/297.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.2.2-cp311-none-macosx_10_9_x86_64.whl (150.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.8/150.8 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_x86_64.whl (14 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpmath, sympy, networkx, MarkupSafe, jinja2, torch, accelerate\n",
            "Successfully installed MarkupSafe-2.1.5 accelerate-0.29.2 jinja2-3.1.3 mpmath-1.3.0 networkx-3.3 sympy-1.12 torch-2.2.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers\n",
        "%pip install datasets\n",
        "%pip install neo4j\n",
        "%pip install langchain\n",
        "%pip install python-dotenv\n",
        "%pip install langchain_community\n",
        "%pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "S9KQEAuwo7Jr"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/joseruiz/Triage App/Medical-Knowledge-Graph/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import json\n",
        "import numpy as np\n",
        "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from configparser import ConfigParser\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ISWK2kiOqU3n"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset('dmacres/mimiciii-hospitalcourse-meta')\n",
        "train_dataset = dataset['train']\n",
        "test_dataset = dataset['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZfAEm2aIqU6q"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject_id</th>\n",
              "      <th>hadm_id</th>\n",
              "      <th>target_text</th>\n",
              "      <th>extractive_notes_summ</th>\n",
              "      <th>n_notes</th>\n",
              "      <th>notes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19278</td>\n",
              "      <td>159960.0</td>\n",
              "      <td>Patient was admitted to the neurosurgery servi...</td>\n",
              "      <td>There remains some low attenuation right subdu...</td>\n",
              "      <td>6</td>\n",
              "      <td>[{'category': 'Nursing/other', 'chartdate': '2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>82177</td>\n",
              "      <td>176262.0</td>\n",
              "      <td>38 y/o female with history of autoimmune disea...</td>\n",
              "      <td>Sinus arrhythmiaSince previous tracing of , th...</td>\n",
              "      <td>2</td>\n",
              "      <td>[{'category': 'ECG', 'chartdate': '2151-03-22 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22500</td>\n",
              "      <td>127625.0</td>\n",
              "      <td>The patient was admitted to the Trauma Team fo...</td>\n",
              "      <td>NEEDS ENCOURAGEMENT FOR FLD INTAKE.GU: VOIDING...</td>\n",
              "      <td>5</td>\n",
              "      <td>[{'category': 'Nursing/other', 'chartdate': '2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>66532</td>\n",
              "      <td>127137.0</td>\n",
              "      <td>62 yo F PMH of afib, TIA, memory loss s/p hypo...</td>\n",
              "      <td>Q2-3 hrs;no   desating,gets resp distress that...</td>\n",
              "      <td>180</td>\n",
              "      <td>[{'category': 'Nursing', 'chartdate': '2103-03...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>95143</td>\n",
              "      <td>127296.0</td>\n",
              "      <td>The patient developed a moderate to large circ...</td>\n",
              "      <td>Thereis brief right atrial diastolic invaginat...</td>\n",
              "      <td>11</td>\n",
              "      <td>[{'category': 'Radiology', 'chartdate': '2156-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   subject_id   hadm_id                                        target_text  \\\n",
              "0       19278  159960.0  Patient was admitted to the neurosurgery servi...   \n",
              "1       82177  176262.0  38 y/o female with history of autoimmune disea...   \n",
              "2       22500  127625.0  The patient was admitted to the Trauma Team fo...   \n",
              "3       66532  127137.0  62 yo F PMH of afib, TIA, memory loss s/p hypo...   \n",
              "4       95143  127296.0  The patient developed a moderate to large circ...   \n",
              "\n",
              "                               extractive_notes_summ  n_notes  \\\n",
              "0  There remains some low attenuation right subdu...        6   \n",
              "1  Sinus arrhythmiaSince previous tracing of , th...        2   \n",
              "2  NEEDS ENCOURAGEMENT FOR FLD INTAKE.GU: VOIDING...        5   \n",
              "3  Q2-3 hrs;no   desating,gets resp distress that...      180   \n",
              "4  Thereis brief right atrial diastolic invaginat...       11   \n",
              "\n",
              "                                               notes  \n",
              "0  [{'category': 'Nursing/other', 'chartdate': '2...  \n",
              "1  [{'category': 'ECG', 'chartdate': '2151-03-22 ...  \n",
              "2  [{'category': 'Nursing/other', 'chartdate': '2...  \n",
              "3  [{'category': 'Nursing', 'chartdate': '2103-03...  \n",
              "4  [{'category': 'Radiology', 'chartdate': '2156-...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(train_dataset)\n",
        "df.head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-_0Gb_0YyEXb"
      },
      "outputs": [],
      "source": [
        "unique_values = df['subject_id'].unique()\n",
        "df_unique_values = df[df['subject_id'].isin(unique_values)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MYFT9nQ9qU9Y"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([19278, 82177, 22500, ..., 22217, 25557, 22734])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['subject_id'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cn1ys-9vqU_6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    24993.000000\n",
              "mean     35303.249510\n",
              "std      28582.486807\n",
              "min          9.000000\n",
              "25%      12692.000000\n",
              "50%      25526.000000\n",
              "75%      56996.000000\n",
              "max      99995.000000\n",
              "Name: subject_id, dtype: float64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['subject_id'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "S_Dul89_qVCz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "subject_id\n",
              "109      26\n",
              "13033    20\n",
              "11861    19\n",
              "5727     15\n",
              "7809     14\n",
              "         ..\n",
              "11844     1\n",
              "65390     1\n",
              "64715     1\n",
              "57215     1\n",
              "22734     1\n",
              "Name: count, Length: 21104, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['subject_id'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Sb2CL60pqVFK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Column 'subject_id' has 0 null value(s).\n",
            "Column 'hadm_id' has 0 null value(s).\n",
            "Column 'target_text' has 0 null value(s).\n",
            "Column 'extractive_notes_summ' has 0 null value(s).\n",
            "Column 'n_notes' has 0 null value(s).\n",
            "Column 'notes' has 0 null value(s).\n"
          ]
        }
      ],
      "source": [
        "for column in df.columns:\n",
        "    null_values = df[column].isnull().sum()\n",
        "    print(f\"Column '{column}' has {null_values} null value(s).\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Qv1uk3xRqVIC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Column 'subject_id' has target_text\n",
            "was            343570\n",
            "and            311222\n",
            "to             260795\n",
            "the            249322\n",
            "of             198230\n",
            "                ...  \n",
            "walker/cane         1\n",
            "cental              1\n",
            "w/staples.          1\n",
            "Epidermis           1\n",
            "givers              1\n",
            "Name: count, Length: 181168, dtype: int64 word(s).\n",
            "Column 'hadm_id' has target_text\n",
            "was            343570\n",
            "and            311222\n",
            "to             260795\n",
            "the            249322\n",
            "of             198230\n",
            "                ...  \n",
            "walker/cane         1\n",
            "cental              1\n",
            "w/staples.          1\n",
            "Epidermis           1\n",
            "givers              1\n",
            "Name: count, Length: 181168, dtype: int64 word(s).\n",
            "Column 'target_text' has target_text\n",
            "was            343570\n",
            "and            311222\n",
            "to             260795\n",
            "the            249322\n",
            "of             198230\n",
            "                ...  \n",
            "walker/cane         1\n",
            "cental              1\n",
            "w/staples.          1\n",
            "Epidermis           1\n",
            "givers              1\n",
            "Name: count, Length: 181168, dtype: int64 word(s).\n",
            "Column 'extractive_notes_summ' has target_text\n",
            "was            343570\n",
            "and            311222\n",
            "to             260795\n",
            "the            249322\n",
            "of             198230\n",
            "                ...  \n",
            "walker/cane         1\n",
            "cental              1\n",
            "w/staples.          1\n",
            "Epidermis           1\n",
            "givers              1\n",
            "Name: count, Length: 181168, dtype: int64 word(s).\n",
            "Column 'n_notes' has target_text\n",
            "was            343570\n",
            "and            311222\n",
            "to             260795\n",
            "the            249322\n",
            "of             198230\n",
            "                ...  \n",
            "walker/cane         1\n",
            "cental              1\n",
            "w/staples.          1\n",
            "Epidermis           1\n",
            "givers              1\n",
            "Name: count, Length: 181168, dtype: int64 word(s).\n",
            "Column 'notes' has target_text\n",
            "was            343570\n",
            "and            311222\n",
            "to             260795\n",
            "the            249322\n",
            "of             198230\n",
            "                ...  \n",
            "walker/cane         1\n",
            "cental              1\n",
            "w/staples.          1\n",
            "Epidermis           1\n",
            "givers              1\n",
            "Name: count, Length: 181168, dtype: int64 word(s).\n"
          ]
        }
      ],
      "source": [
        "for column in df.columns:\n",
        "  word_count = df['target_text'].str.split().explode().value_counts()\n",
        "  print(f\"Column '{column}' has {word_count} word(s).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bS_y_HmKqVKW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "target_text\n",
              "was            343570\n",
              "and            311222\n",
              "to             260795\n",
              "the            249322\n",
              "of             198230\n",
              "                ...  \n",
              "walker/cane         1\n",
              "cental              1\n",
              "w/staples.          1\n",
              "Epidermis           1\n",
              "givers              1\n",
              "Name: count, Length: 181168, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_count = df['target_text'].str.split().explode().value_counts()\n",
        "word_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQMneakuqVM2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Kp-trtgCDZfa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('subject_id',\n",
              "  {0: 19278,\n",
              "   1: 82177,\n",
              "   2: 22500,\n",
              "   3: 66532,\n",
              "   4: 95143,\n",
              "   5: 86645,\n",
              "   6: 26523,\n",
              "   7: 5495,\n",
              "   8: 4113,\n",
              "   9: 69472}),\n",
              " ('target_text',\n",
              "  {0: \"Patient was admitted to the neurosurgery service and underwent an emergent R craniotomy with drainage of his subdural hemorrhage. Postoperatively he was transferred to the intensive care unit extubated and stable. He was maintained on dilantin for seizure prophylaxis, his blood pressure was controlled and he was monitored with close neuro checks. He was also maintained on prn ativan for prevention of alcohol withdrawal considering patient's significant drinking history. A postoperative CT scan demonstrated postoperative changes and an improvement in his subdural. He remained stable, his diet was advanced and he was awake and appropriate. He was found to have a simple urinary tract infection and was treated with ciprofloxacin. He was evaluated by both occupational and physical therapy and cleared for home. He was discharged to home on POD2 in good condition and will follow up in Dr. clinic for wound  in approximately 10 days.\",\n",
              "   1: \"38 y/o female with history of autoimmune diseases (Crohn's vasculitis, psoriasis) with autoimmune hemolytic anemia following fever. . 1. Autoimmune Hemolytic Anemia: Etiology includes acquired post infectious autoimmune process, reactive autoimmune process after tappering steroids. Presented febrile. WBC was elevated in the setting of hemolysis and elevated bone marow turnover. Fevers could have been due to vasculitis, infection (unclear source). She received 6 units of PRBC's. She was treated initially with IV solumedrol, to which she had some psychosis. She was later changed to Prednisone 80 mg PO QD. Her hemolysis labs slowly improved. Her HCT was stable in the mid 20's. She was treated with B12 and folate. Hematology will follow her as an outpatient. Would recommend watching for fevers once off steroids. . 2. Non Gap Metabolic Acidosis: Likely lactic acidosis from cell lysis, as LDH was elevated. She was treated with IV fluids- Lactated Ringers. . 3. Elevated Blood Sugars: Likely due to steroids. She was covered with insulin based on a sliding scale. . 4. Vasculitis: Much improved per patient with prednisone. Unclear . Diagnosed and followed at B&W Hospital. . 5. Crohn's: Stable. . 6. Psoriasis: Stable. . FULL CODE\",\n",
              "   2: \"The patient was admitted to the Trauma Team for observation.  Secondary to patient's age and multiple rib fractures with associated morbidity, the Anesthesia Department was consulted to perform epidural anesthesia on the patient to aid in the aggressive pulmonary toilet.  The patient declined this.  The patient was treated with morphine until the morning.  Secondary to patient's persistent flank and back pain, the Department of Orthopedics was consulted, L1-L2 transverse processes fractures with stable injuries that required symptomatic treatment and recommended patient being fitted with thoracolumbar corset for comfort.  The patient also received CT imaging of the cervical spine. Findings were notable for multiple areas of anterolisthesis of a mild degree at C3-C4, C4-C5, and C6-C7, C7-T1.  No fractures were identified.  Spinous process of C3 was displaced slightly forward.  DENS intact.  Lateral masses of C1 were well lined on C2 without any soft tissue swelling. The patient also received Flex X plain radiograph and plain film trauma series of the cervical spine, which were negative.  The patient continued to improve during the remainder of the hospital stay under good pain management with morphine and dilaudid.  The patient worked with PT and continued to make an improvement.  Now, the patient is stable with improved pain control.  The patient will be discharged to rehabilitation to progress with independence in mobility.  The patient should followup with the Trauma Clinic in two weeks' time.\",\n",
              "   3: \"62 yo F PMH of afib, TIA, memory loss s/p hypoglycemic coma, chronic low back pain, anemia, GERD, asthma recently admitted with subarachnoid hemorrhage  readmitted with acute change in mental status  acute on chronic hypercarbic respiratory failure . # Acute on chronic hypercarbic respiratory failure: Patient was felt to have a multifactorial etiologies for her respirtory failure including central and obstructive apnea, a chronic paralyzed R hemidiaphragm, and obesity hypoventilation which all contibuted to her difficulty with respiration. She underwent tracheostomy and had significant improvement in oxygenation and acid base status. She remained mostly on AC vent settings with daily pressure support trials which were sometimes limited by hypercarbia. In addition, during pressure support trials she occasionally desat in setting of decreasing TV to 280's. In addition, she would benefit from diamox PRN to aid with alkalosis while on vent.  She was also noted to be volume overloaded with a length of stay net +7L. Her CXR was suggestive of pulmonary edema, and lasix gtt was started on  with goal for 1-2L fluid removal. After discharge, her lasix gtt should be adjusted to pulmonary exam. . # Tracheal tear: On , pt underwent a CTA to rule out PE given tachycardia and hypoxia. CT revealed and abnl trachea. The next day, patient was taken to OR for fiberoptic intubation and rigid bronch which showed a 5cm tracheal tear. IP was involved and recommended prolonged intubation to allow tear to heal as well as ppx abx with Unasyn and fluconazole (both started on ) for total 10 day course (last day ). After further discussion with family and IP, it was felt that the most cautious management for be for tracheostomy to bypass the area of the tear given that she is at very high risk for repeated intubation and the risk of causing perforation of the tear would be greater in setting of re-intubation. She tolerated the tracheostomy. She will need follow-up with Dr.   in  weeks. Trach can NOT be changed until after . Sutures can be removed after . . # ? Mass in L hilum: Pt reportedly has a mass on OSH chest CT in L hilum at location of bleed which was noticed by IP during bronchoscopy. This will need to be assessed with contrast CT as an outpatient. Please arrange with her PCP to have this follow-up. . # Recent Left temporal hemorrhage: Unclear etiology, less likely due to trauma, more likely  HTN and anticoagulation. No evidence of rebleeding or new bleed on head CT. She will need follow-up with neurosurgery (Dr.  , ) within one month post-discharge. At that time, he will re-evaluate restarting coumadin and aspirin.  She was maintained on keppra for seizure ppx in setting of bleed. . # Paroxysmal Atrial fibrillation: HR remained mostly well controlled int he 60's. Coumadin and aspirin were held given recent hemorrhage.  She will need to discuss restarting anticoagulation with neurosurgeon. . # HTN: Her BP was variable. Her regimen was adjusted to include enalapril 30 mg daily and hydralazine 25 mg PO QID. Her metoprolol was intermittently held given bradycardia, but it was felt that she does need nodal blockade for her paroxsysmal afib. . # Altered mental status: Improved steadily over hospital course, but pt still frequently confused. Per her husband, this is near her baseline following anoxic brain injury and hypoglycemia in the past. Head CT unchanged, Chest CTA w/o PE, no evidence of MI, TTE w/ nl EF, UA unremarkable. . # Hypernatremia: She was found to be intermittently hypernatremia and her free water flushes were adjusted accordingly.\",\n",
              "   4: 'The patient developed a moderate to large circumferential pericardial effusion, for which he underwent pericardiocentesis in the cath lab.  Procedure was complicated by RV laceration. He became hemodynamically unstable with systolic blood pressure in the 60-80mmHg range, requiring dopamine and volume resuscitation.  He was rushed to the operating room for mediastinal exploration and repair of right ventricle laceration.  Overall he tolerated the procedure well, and post-operatively was transferred to the CVICU for observation and invasive monitoring.  Vancomycin was used for surgical antibiotic prophylaxis given the preoperative length of stay of greater than 24 hours.  POD 1 found the patient extubated, alert and oriented and breathing comfortably.  The patient was neurologically intact and hemodynamically stable on no inotropic or vasopressor support.  Beta blocker was initiated and the patient was gently diuresed toward the preoperative weight.  The patient was transferred to the telemetry floor for further recovery.  He did develop post-operative atrial fibrillation, and amiodarone was initiated.  Chest tubes were discontinued without complication.  The patient was evaluated by the physical therapy service for assistance with strength and mobility.  By the time of discharge on POD 4 the patient was ambulating freely, the wound was healing and pain was controlled with oral analgesics.  The patient was discharged to home in good condition with appropriate follow up instructions.',\n",
              "   5: '56 year old male with a past medical history of cerebral atriaovenous malformation (AVM) staus post coiling with residual left sided hemipareisis and disorientation with known C. Diff colitis s/p day 4 of treatment with falgyl and spiked a temperature to 103.8 in the ED and vomiting and diarreha and leukocytosis, found to have sepsis due to a urinary tract infection and C. diff colitis.',\n",
              "   6: \"(By issue)  1.  Right lower extremity cellulitis and ulcerations - The patient was admitted to the Podiatry Service on  for the cellulitis of the right lower extremity.  On admission she was started on Vancomycin, Levaquin and Flagyl for broad coverage.  Blood cultures and wound cultures were taken.  Both grew out Escherichia coli. In order to more specifically cover, the patient's antibiotics were changed to Oxacillin and Ceftriaxone.  The patient has also had hardware in her right ankle and because of the possibility that this was seated, the patient required surgery.  Her Coumadin was discontinued and once her INR had decreased close to baseline, she was taken to the Operating Room for hardware removal.  This was done on . Postoperatively the patient is stable on Oxacillin and Ceftriaxone until two days after the operation.  Then due to concern for pneumonia her antibiotic coverage was changed to Zosyn and Vancomycin.  She continued this for three days and then was only on Zosyn.  Her right lower extremity was in a vacuum-assisted closure dressing and continued to improve, healing by secondary intention.  She has been followed by Podiatry.  Her left lower extremity ulcer also continued to improve.  X-rays showed an old fracture without any changes in the left foot.  The patient did not have any further signs of worsening cellulitis or infection of her extremities.  2.  Respiratory - On , the patient developed hypoxia with an oxygen saturation of 80% on room air and hypertension with systolic blood pressure in the 190s.  She was also complaining of a new productive cough.  Chest x-ray done on that day was consistent with congestive heart failure and the patient was given Lasix.  There is also question of a right lower lobe infiltrate on the chest x-ray, so Azithromycin was initially added to her regimen of Ceftriaxone and Oxacillin. On the same day, the patient also developed mental status changes which was possibly thought to be related to her hypoxia.  At this point, due to concern for pneumonia and respiratory compromise, the patient's antibiotic coverage was changed to Vancomycin and Zosyn and she was transferred to the Intensive Care Unit for closer monitoring.  She was never intubated.  She was continued on Zosyn and Vancomycin and a sputum culture was obtained.  The sputum culture showed  and did not grow out any bacteria.  The patient's respiratory status improved with decrease in oxygen requirements.  Once the sputum culture was negative for any bacteria and there was no evidence of Methicillin-resistant Staphylococcus aureus her Vancomycin was discontinued.  She was continued on Zosyn for treatment of possible aspiration pneumonia and for her cellulitis.  3.  Congestive heart failure - The patient required Lasix intermittently for mild hypoxia and crackles on lung examination indicative of congestive heart failure.  She was also on Zestril 20 mg b.i.d. initially and then titrated up for afterload reduction.  Her blood pressure was labile but was controlled with Catapres, Lopressor, and Zestril.  4.  Anticoagulation - The patient's Coumadin was discontinued as was previously mentioned in order to be taken to the Operating Room.  While off Coumadin the patient was on a heparin drip for her history of deep vein thrombosis and pulmonary embolism.  Once it was decided that no further procedures would be done by Podiatry she was restarted on Coumadin.  Her heparin drip was continued until her INR would be in the goal range of 2 to 3.  5.  Chronic back pain - The patient had chronic back for which she had been on Nubain at home.  While in the hospital she was started on a morphine PCA.  Initially there was no basal rate, however, the patient was not using the PCA and therefore basal rate was added.  Plan was for the patient to have a morphine placed by Neurosurgery once her active acute issues are cleared.  This will probably be done after discharge.  She was also on Baclofen, Tizanidine and Vioxx for her pain.  6.  Hypothyroidism - The patient was continued on Levoxyl.  7.  Psyche - The patient was on Celexa and Klonopin.  8.  Dysphagia - The patient had a swallowing study previously done in , in order to evaluate symptoms of dysphagia. This showed a possible offer for esophageal sphincter dysfunction, no further workup was done at the time.  On this admission there is a question of aspiration pneumonia and the patient was re-evaluated by the swallowing service.  Again there was no evidence of aspiration but evidence that there was upper esophageal dysfunction.  The patient will require a gastroenterology follow up for workup and possible dilatation.  For now, she will be on a soft diet with frequent liquids when eating.  9.  Anemia - The patient has a history of chronic anemia requiring blood transfusions.  While in the hospital she also had periods of time when her hematocrit was below 30.  There were no signs of active bleeding.  The iron studies showed a mixed picture with decreased iron and TIBC and elevated Ferritin.  The patient's iron to TIBC ratio was low suggesting a possible combination of iron deficiency anemia, anemia of chronic disease and possibly anemia related to the patient's hypothyroidism.  The patient was given blood transfusions as needed to maintain her hematocrit greater than 30, given her history of congestive heart failure.  10. Diabetes Type 2 - The patient was continued on a sliding scale of insulin.  Her Metformin was held when she was not eating.  It will be restarted when she is eating more stabilely.\",\n",
              "   7: '78 y/o M with PMHx of CAD s/p CABG & MI, Metastatic Carcinoid and chronic abd/back pain who presents with decreased po intake, diarrhea, lethargy and hypotension found to have colitis on CT. His hospital course showed a progressive decline in function where his mental status and physical condition slowly declined despite treatment of his medical problems. . AMS: Variable course over his stay, likely multifactorial with possible etiologies including narcotics, toxic/metabolic related to renal failure. It appears to be most consistent with delirium. Had CT head with contrast on , but this does not definitively r/o brain metastases. Neuro exam is nonfocal. BUN has improved over the last 10 days. At d/c continued to be AO X 1, but has remained clear on his intentions to not escalate care with the desire to return home and be with family.',\n",
              "   8: \"Patient is a 45 y/o female with CAD s/p CABG, diastolic HF and kidney transplant presenting from OSH with shortness of breath. . # CORONARIES:  Known CAD s/p CABG in .  Was cathed on admission which showed no change from previous cath in . Report was as follows: Coronary angiography in this right dominant system revealed diffuse multivessel coronary artery disease.  The LMCA had no significant stenosis.  The LAD had a 70% mid-portion stenosis after the D1 branch with competitive flow from a patent LIMA that filled the distal vessel. The LCX had severe diffuse disease in the mid-portion extending into a distal branching OM that was unchanged compared with prior caths in  and  performed after known SVG-OM occlusion.  The RCA was not injected.  The SVG-->R-PDA was patent with filling of a diffusely diseased distal RCA.  The LIMA-LAD was patent. Resting hemodynamics performed on intravenous nitroglycerine revealed slightly  left and right filling pressures with mean RA pressure of 10 mmHg and mean PCWP of 15 mmHg. No intervention was performed at this time.  Patient denied chest pain or anginal equivalent while in hospital.  The patient underwent a repeat cardiac cath on  with PTCA of the left circumflex artery, which was thought to be contributing to the patient's symptoms. Final angiography revealed 30% residual stenosis, no angiographically apparent dissection, and TIMI 3 flow.  Patient was continued on telemetry without events.  She was continued on aspirin, atorvastatin, plavix, and metoprolol was changed to 12.5 mg XL. . # PUMP:  History of diastolic dysfunction now presented with CHF exacerbation.  ECHO  showed low normal LVEF (50-55%), Grade II (moderate) LV diastolic dysfunction, and Moderate (2+) mitral regurgitation.  The patient also had an episode of flash pulmonary edema, which responded to lasix diuresis and temporary NRB mask.  Patient was treated with metoprolol 12.5 XL, nifedipine was changed to Lisinopril and Lasix was increased to 40 mg daily.  In addition, the patient was extensively counseled on self-monitoring fluid status with daily self weights and titration of lasix as needed to prevent further episodes of pulmonary edema. Weight at discharge was 59 kg. . # RHYTHM:  Patient remained in NSR. Her metoprolol was changed from 50 mg  to 12.5 mg extended release. . # Immune Suppression: Patient is s/p living donor kidney transplant.  She was continued on sirolimus 3 mg daily and tacrolimus 2 mg twice daily, as per home regimen.  Home dose of prednisone (4mg daily) and bactrim prophylaxis continued as well. . # Diabetes Mellitus Type I: Last A1C on  was 8.7%.  During admission, pt was continued on Lantus plus sliding scale insulin with good blood glucose control. She has a follow-up appt with her endocrinologist in 1 week. . # Chronic Renal Disease: Patient is s/p kidney transplant. Her creatinine over the last year has ranged from 0.8-1.1. During the course of her hospitalization, the patient had a Cr mildly  from baseline, consistent with acute on chronic renal failure, likely secondary to contrast administration from multiple cardiac catheterizations.  On discharge, Cr was 1.3. . # Hypertension: Patient was initially continued on home doses of metoprolol and nifedipine extended release.  After diuresis, patient had an episode of hypotension and nifedipine was discontinued, and metoprolol 50 mg  changed to 12.5 mg XR po daily. Lisinopril was added for afterload reduction and can be tapered up as needed to keep SBP in goal range of 120-140. . # Depression: continued on home medications of bupropion and citalopram. She has f/u with her ouptpt psychiatrist. . # Pain: Questionable allergy to codeine- patient reports nausea/vomiting but has been taking oxycodone recently for ankle fracture. Discharged on Ultram for left leg pain. Note that pt has tolerated oxycodone Po for treatment of her left leg pain. . # Insomnia: Continued on home dose of trazodone. . # Nausea: Continued on reglan and zofran. . # Osteoporosis: Continued vitamin D and calcium.\",\n",
              "   9: 'This 57-year-old patient with recent syncopal attacks was investigated and was found to have a critical aortic stenosis, moderate mitral regurgitation with preserved left ventricular function. The patient was brought to the operating room on  where the patient underwent an aortic valve replacement with size 23 St.  Regent mechanical valve and mitral valve repair with size 26  annuloplasty band. Overall the patient tolerated the procedure well and post-operatively was transferred to the CVICU in stable condition for recovery and invasive monitoring.  The patient was diuresed on post operative day 1 and ventilator was weaned. Early POD 2 found the patient extubated, alert and oriented and breathing comfortably.  She was weaned off her vasoactive medications on post operative day 2, including epinephrine and Neosynephrine. Beta blocker was initiated and the patient was gently diuresed toward the preoperative weight. She went into a rapid atrial fibrillation and was loaded with Amiodarone in the CVICU. The patient was transferred to the telemetry floor for further recovery. Beta blockers were increased and Diltiazem was added for better heart rate control. Coumadin was started for atrial fibrillation and mechanical AVR.  She was therapeutic with her INR at the time of discharge with a goal INR 2.5-3.5. Chest tubes and pacing wires were discontinued without complication. Cipro was started for a Klebsiella UTI (sensitive to Cipro).  She was completing a 3 day course at the time of discharge and had a repeat urine culture prior to discharge which was pending. An echocardiogram was done on  and results were pending at the time of this discharge summary. Upon discharge Zaroxyln was stopped and Lasix was changed to 40 mg po BID due to slight rise in BUN and creatinine.  Her fluid status should be monitored closely and Lasix dosing is to be reevaluated in 2 weeks based on need for further diuresis.   The patient was evaluated by the physical therapy service for assistance with strength and mobility.  By the time of discharge on POD 9 the patient was ambulating with assistance, she was tolerating a full oral diet, the wound was healing and pain was controlled with Ultram.  The patient was discharged to  House Rehab in  in good condition with appropriate follow up appointment instructions and lab work instructions.'})]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "short_target_data = df[['subject_id','target_text']].head(10)\n",
        "\n",
        "short_target_dict = short_target_data.to_dict()\n",
        "\n",
        "short_target_list = list(short_target_dict.items())\n",
        "short_target_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6h2vcCR-4eoR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        }
      ],
      "source": [
        "pipe = pipeline(\"token-classification\", model=\"Clinical-AI-Apollo/Medical-NER\", aggregation_strategy='simple')\n",
        "\n",
        "\n",
        "result_list = {}\n",
        "for index, row in short_target_data.iterrows():\n",
        "    subject_id = row['subject_id']\n",
        "    target = row['target_text']\n",
        "\n",
        "    result = pipe(target)\n",
        "    scores = [res['score'] for res in result]\n",
        "    median_score = np.median(scores)\n",
        "\n",
        "    if target is not result_list:\n",
        "      result_list[target] = []\n",
        "\n",
        "    for res in result:\n",
        "      if res['score'] >= median_score:\n",
        "        entity_info = {\n",
        "            'Entity': res['entity_group'],\n",
        "            'Word': res['word'],\n",
        "            'Score': str(res['score'])\n",
        "        }\n",
        "        result_list[target].append(entity_info)\n",
        "\n",
        "entities_list = [{'Id': subject_id, 'Text': text, 'Entities': entities} for text, entities in result_list.items()]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gcRHYqaiUmeJ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Id': 69472,\n",
              " 'Text': \"Patient was admitted to the neurosurgery service and underwent an emergent R craniotomy with drainage of his subdural hemorrhage. Postoperatively he was transferred to the intensive care unit extubated and stable. He was maintained on dilantin for seizure prophylaxis, his blood pressure was controlled and he was monitored with close neuro checks. He was also maintained on prn ativan for prevention of alcohol withdrawal considering patient's significant drinking history. A postoperative CT scan demonstrated postoperative changes and an improvement in his subdural. He remained stable, his diet was advanced and he was awake and appropriate. He was found to have a simple urinary tract infection and was treated with ciprofloxacin. He was evaluated by both occupational and physical therapy and cleared for home. He was discharged to home on POD2 in good condition and will follow up in Dr. clinic for wound  in approximately 10 days.\",\n",
              " 'Entities': [{'Entity': 'CLINICAL_EVENT',\n",
              "   'Word': 'admitted',\n",
              "   'Score': '0.9203476'},\n",
              "  {'Entity': 'NONBIOLOGICAL_LOCATION',\n",
              "   'Word': 'neurosurgery service',\n",
              "   'Score': '0.8626597'},\n",
              "  {'Entity': 'DETAILED_DESCRIPTION', 'Word': 'R', 'Score': '0.8046878'},\n",
              "  {'Entity': 'THERAPEUTIC_PROCEDURE',\n",
              "   'Word': 'craniotomy',\n",
              "   'Score': '0.9133733'},\n",
              "  {'Entity': 'THERAPEUTIC_PROCEDURE', 'Word': 'drainage', 'Score': '0.83775'},\n",
              "  {'Entity': 'BIOLOGICAL_STRUCTURE',\n",
              "   'Word': 'subdural',\n",
              "   'Score': '0.97473407'},\n",
              "  {'Entity': 'CLINICAL_EVENT', 'Word': 'transferred', 'Score': '0.86672777'},\n",
              "  {'Entity': 'NONBIOLOGICAL_LOCATION',\n",
              "   'Word': 'intensive care unit',\n",
              "   'Score': '0.9036899'},\n",
              "  {'Entity': 'THERAPEUTIC_PROCEDURE',\n",
              "   'Word': 'extubated',\n",
              "   'Score': '0.8991975'},\n",
              "  {'Entity': 'MEDICATION', 'Word': 'dilantin', 'Score': '0.97489303'},\n",
              "  {'Entity': 'DIAGNOSTIC_PROCEDURE',\n",
              "   'Word': 'blood pressure',\n",
              "   'Score': '0.9775475'},\n",
              "  {'Entity': 'LAB_VALUE', 'Word': 'controlled', 'Score': '0.94274276'},\n",
              "  {'Entity': 'DIAGNOSTIC_PROCEDURE',\n",
              "   'Word': 'neuro checks',\n",
              "   'Score': '0.985191'},\n",
              "  {'Entity': 'MEDICATION', 'Word': 'prn ativan', 'Score': '0.7997188'},\n",
              "  {'Entity': 'DIAGNOSTIC_PROCEDURE', 'Word': 'CT scan', 'Score': '0.88590086'},\n",
              "  {'Entity': 'BIOLOGICAL_STRUCTURE',\n",
              "   'Word': 'subdural',\n",
              "   'Score': '0.96503323'},\n",
              "  {'Entity': 'LAB_VALUE', 'Word': 'advanced', 'Score': '0.8994377'},\n",
              "  {'Entity': 'BIOLOGICAL_STRUCTURE',\n",
              "   'Word': 'urinary tract',\n",
              "   'Score': '0.9388086'},\n",
              "  {'Entity': 'MEDICATION', 'Word': 'ciprofloxacin', 'Score': '0.9611376'},\n",
              "  {'Entity': 'DIAGNOSTIC_PROCEDURE',\n",
              "   'Word': 'occupational',\n",
              "   'Score': '0.89161336'},\n",
              "  {'Entity': 'CLINICAL_EVENT', 'Word': 'discharged', 'Score': '0.8779562'},\n",
              "  {'Entity': 'LAB_VALUE', 'Word': 'good', 'Score': '0.8184061'},\n",
              "  {'Entity': 'CLINICAL_EVENT', 'Word': 'follow', 'Score': '0.7847724'},\n",
              "  {'Entity': 'NONBIOLOGICAL_LOCATION',\n",
              "   'Word': 'Dr. clinic',\n",
              "   'Score': '0.8718838'}]}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# for result in result_list:\n",
        "#   print(result['entity_group'])\n",
        "entities_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "kJV80tNWm8NL"
      },
      "outputs": [],
      "source": [
        "prompt_message =  \"Based on the text and entities, generate relationships terms between each those entities for a knowledge graph. Add create a new key value paired with the key called RELATION and the value will be the generated reponse.\"\n",
        "\n",
        "\n",
        "# Constructing the prompt variable with both text and prompt_message\n",
        "prompt_template = [\n",
        "    prompt_message,\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"text\"\n",
        "    }\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5zWqJyxQ4euz"
      },
      "outputs": [],
      "source": [
        "with open(\"entity_extraction_results.json\", \"w\") as outfile:\n",
        "    json.dump(entities_list, outfile, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ir3kT9EodhtG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
            "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
            "Loading checkpoint shards: 100%|██████████| 4/4 [02:31<00:00, 37.98s/it]\n"
          ]
        }
      ],
      "source": [
        "config=ConfigParser()\n",
        "config.read('.config')\n",
        "api_token = config['DEFAULT']['HF_API_TOKEN']\n",
        "\n",
        "model_name_or_path = \"google/gemma-7b\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
        "                                             low_cpu_mem_usage=True, token=api_token)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, token=api_token)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Ar9xO8g-fqlg"
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=10\n",
        ")\n",
        "\n",
        "hf = HuggingFacePipeline(pipeline=pipe)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgbNI9f2WKx0"
      },
      "outputs": [],
      "source": [
        "# prompt = \"What are the symptoms of diabetes ?\"\n",
        "# prompt_template=f'''\n",
        "# <|system|>: You are a helpful medical assistant created by M42 Health in the UAE.\n",
        "# <|prompter|>:{prompt}\n",
        "# <|assistant|>:\n",
        "# '''\n",
        "\n",
        "# response = hf.generate_text(prompt)\n",
        "# print(response)\n",
        "\n",
        "# # input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
        "# # output = hf.generate(inputs=input_ids, temperature=0.7, do_sample=True,eos_token_id=tokenizer.eos_token_id, pad_token_id=tokenizer.pad_token_id, max_new_tokens=512)\n",
        "# # print(tokenizer.decode(output[0]))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Both `max_new_tokens` (=10) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[26], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m filled_prompt \u001b[38;5;241m=\u001b[39m prompt_template\u001b[38;5;241m.\u001b[39mformat(prompt)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Generate a response using the pipeline object\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mhf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilled_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
            "File \u001b[0;32m~/Triage App/Medical-Knowledge-Graph/.venv/lib/python3.11/site-packages/transformers/pipelines/text_generation.py:240\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(chats, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Triage App/Medical-Knowledge-Graph/.venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1206\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1199\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1200\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1203\u001b[0m         )\n\u001b[1;32m   1204\u001b[0m     )\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Triage App/Medical-Knowledge-Graph/.venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1213\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1212\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1213\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1214\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
            "File \u001b[0;32m~/Triage App/Medical-Knowledge-Graph/.venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1112\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1110\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1111\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1112\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1113\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m~/Triage App/Medical-Knowledge-Graph/.venv/lib/python3.11/site-packages/transformers/pipelines/text_generation.py:327\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m         generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prefix_length\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# BS x SL\u001b[39;00m\n\u001b[0;32m--> 327\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "File \u001b[0;32m~/Triage App/Medical-Knowledge-Graph/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Triage App/Medical-Knowledge-Graph/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1527\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massisted_decoding(\n\u001b[1;32m   1510\u001b[0m         input_ids,\n\u001b[1;32m   1511\u001b[0m         candidate_generator\u001b[38;5;241m=\u001b[39mcandidate_generator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1524\u001b[0m     )\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1526\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_greedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1542\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
            "File \u001b[0;32m~/Triage App/Medical-Knowledge-Graph/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:2411\u001b[0m, in \u001b[0;36mGenerationMixin._greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2408\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2410\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2411\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2412\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2414\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2415\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2416\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2419\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
            "File \u001b[0;32m~/Triage App/Medical-Knowledge-Graph/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Triage App/Medical-Knowledge-Graph/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Triage App/Medical-Knowledge-Graph/.venv/lib/python3.11/site-packages/transformers/models/gemma/modeling_gemma.py:1105\u001b[0m, in \u001b[0;36mGemmaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1102\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1118\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1119\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
            "File \u001b[0;32m~/Triage App/Medical-Knowledge-Graph/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Triage App/Medical-Knowledge-Graph/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Triage App/Medical-Knowledge-Graph/.venv/lib/python3.11/site-packages/transformers/models/gemma/modeling_gemma.py:923\u001b[0m, in \u001b[0;36mGemmaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    912\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    913\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    914\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    920\u001b[0m         cache_position,\n\u001b[1;32m    921\u001b[0m     )\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 923\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    933\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
            "File \u001b[0;32m~/Triage App/Medical-Knowledge-Graph/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Triage App/Medical-Knowledge-Graph/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Triage App/Medical-Knowledge-Graph/.venv/lib/python3.11/site-packages/transformers/models/gemma/modeling_gemma.py:658\u001b[0m, in \u001b[0;36mGemmaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    656\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    657\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 658\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    661\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
            "File \u001b[0;32m~/Triage App/Medical-Knowledge-Graph/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Triage App/Medical-Knowledge-Graph/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Triage App/Medical-Knowledge-Graph/.venv/lib/python3.11/site-packages/transformers/models/gemma/modeling_gemma.py:189\u001b[0m, in \u001b[0;36mGemmaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_proj(x))\n",
            "File \u001b[0;32m~/Triage App/Medical-Knowledge-Graph/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Triage App/Medical-Knowledge-Graph/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Triage App/Medical-Knowledge-Graph/.venv/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "prompt = \"What are the symptoms of diabetes ?\"\n",
        "prompt_template = '''\n",
        "Extract the following relationships between the provided entities using the text as context. Please follow the described format:\n",
        "0. ALWAYS COMPLETE THE OUTPUT. Never send partial responses.\n",
        "1. Generate each relationship as triples of head, relationship, and tail. The 'ID' is to be referred to by its value. Relationship properties should be mentioned within brackets as comma-separated. They should follow these relationship types below. You will have to generate as many relationships as needed, as defined below:\n",
        "    Relationship types:\n",
        "    ID|ADMITTED_TO|neurosurgery service\n",
        "    ID|DIAGNOSED_WITH|subdural hemorrhage\n",
        "2. The output should appear as:\n",
        "{\n",
        "    \"relationships\": [\"ID|ADMITTED_TO|Entity\"]\n",
        "}\n",
        "\n",
        "'''\n",
        "\n",
        "# Fill in the prompt template with the prompt\n",
        "filled_prompt = prompt_template.format(prompt)\n",
        "\n",
        "# Generate a response using the pipeline object\n",
        "response = hf.pipeline(filled_prompt, max_length=100)[0][\"generated_text\"]\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "2svvTfk9fGx6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=512) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'generated_text': 'Based on the text and entities, generate relationships terms between each those entities for a knowledge graph. Add create a new key value paired with the key called RELATION and the value will be the generated reponse. The value is sent to the client that includes the ROTC and the key will not be added to them. Use the following syntax to create a new reponse:\\n\\nCreate a new key value Pairing a value from multiple fields with the same key will create new reponse.\\n\\nIf you have the same key, the name will be added to the ROTC.\\n\\nIf you have a different key name, or you have different tokens, or you have two tokens, then create the same new \"value\" from the previous step (create new key for the one you have previously used and add your pair and you will get a new \"listing for it\" after step 3).\\n\\nIn both cases, the output will look like this:\\n\\nA new value will be added to the ROTC and the token will be added.\\n\\nIt is worth noting that when creating a new relationship you can add the same key or token to your existing token or reponse. See this demo\\n\\nRe-generations of properties\\n\\nBefore you add any methods to your relationship, use the create and create new methods. In the example above, you created a link with a value named link as a field and added a value named link as a field. If you want it to generate a new relationship, use the create, create object method. Create objects and return the same information. You can also use the create method to create instances of linked fields, using the create on link attribute instead for each link that you assign a value for.\\n\\nExample:\\n\\ncreate link.setValue(\\'post.description\\') link.setValue(\\'post.\\'name) link.create([post.description],[\\'newName\\',[\\'createdDate\\',\\'/05/2017 01:07:00 AM\\', \\'createdTime\\',\\'/05/2017 01:00:00 PM],); link.create(10); link.create(20, 50);\\n\\nIf you add an instance as a field to a link, you will expect that name to be associated with the post. The name of the link you create will depend on the relation and the name of the post. By default, the Link object is a unique \"meta\". The only thing in the link the link will have is the meta property value, which means the link will be created by the client that creates the relationship and will receive the meta value from the page.\\n\\nLink creation with create.\\n\\nHere\\'s something the client receives'}]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'generated_text': 'Based on the text and entities, generate relationships terms between each those entities for a knowledge graph. Add create a new key value paired with the key called RELATION and the value will be the generated reponse. The value is sent to the client that includes the ROTC and the key will not be added to them. Use the following syntax to create a new reponse:\\n\\nCreate a new key value Pairing a value from multiple fields with the same key will create new reponse.\\n\\nIf you have the same key, the name will be added to the ROTC.\\n\\nIf you have a different key name, or you have different tokens, or you have two tokens, then create the same new \"value\" from the previous step (create new key for the one you have previously used and add your pair and you will get a new \"listing for it\" after step 3).\\n\\nIn both cases, the output will look like this:\\n\\nA new value will be added to the ROTC and the token will be added.\\n\\nIt is worth noting that when creating a new relationship you can add the same key or token to your existing token or reponse. See this demo\\n\\nRe-generations of properties\\n\\nBefore you add any methods to your relationship, use the create and create new methods. In the example above, you created a link with a value named link as a field and added a value named link as a field. If you want it to generate a new relationship, use the create, create object method. Create objects and return the same information. You can also use the create method to create instances of linked fields, using the create on link attribute instead for each link that you assign a value for.\\n\\nExample:\\n\\ncreate link.setValue(\\'post.description\\') link.setValue(\\'post.\\'name) link.create([post.description],[\\'newName\\',[\\'createdDate\\',\\'/05/2017 01:07:00 AM\\', \\'createdTime\\',\\'/05/2017 01:00:00 PM],); link.create(10); link.create(20, 50);\\n\\nIf you add an instance as a field to a link, you will expect that name to be associated with the post. The name of the link you create will depend on the relation and the name of the post. By default, the Link object is a unique \"meta\". The only thing in the link the link will have is the meta property value, which means the link will be created by the client that creates the relationship and will receive the meta value from the page.\\n\\nLink creation with create.\\n\\nHere\\'s something the client receives'}]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# llm_pipeline = pipeline(\"text-generation\")\n",
        "# dependency_results = llm_pipeline(prompt_message, max_length=256, max_new_tokens=512, truncation=True)\n",
        "\n",
        "# print(dependency_results)\n",
        "# dependency_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSc0ox2RX6mx"
      },
      "outputs": [],
      "source": [
        "# Extract relationships based on Named Entities and Dependency Parsing\n",
        "relationships = []\n",
        "\n",
        "for token in dependency_results:\n",
        "    if token['Word'] in entities:\n",
        "        head = token['head']\n",
        "        head_word = dependency_results[head - 1]['word']\n",
        "        if head_word in entities:\n",
        "            relationships.append({\n",
        "                \"source\": head_word,\n",
        "                \"target\": token['word'],\n",
        "                \"relation\": token['dep']\n",
        "            })\n",
        "\n",
        "# Output the relationships as JSON\n",
        "print(json.dumps(relationships, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qduYCYyqVPo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
